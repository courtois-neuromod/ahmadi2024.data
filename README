<!-- vim: syntax=Markdown -->
# Courtois-NeuroMod: friends subdataset, derivatives timeseries for S.Ahmadi 2024 publication

The [Courtois project on Neural Modelling (Courtois NeuroMod)](https://www.cneuromod.ca/) aims at training artificial neural networks using extensive experimental data on individual human brain activity and behavior.


Intermediate  Numpy files were generated in the paper titled [Scaling up ridge regression for brain encoding in a massive individual fMRI dataset](https://arxiv.org/pdf/2403.19421.pdf)

## Multiresolution Time Series Extraction

The fMRI time series data includes three common spatial resolutions for each subject: parcel-wise, ROI-wise, and whole brain. These resolutions are described below:

1. **Parcels:**
   - The preprocessed BOLD time series were averaged across all voxels in each parcel of a parcellation atlas, using the NiftiLabelsMasker masker from Nilearn. We used the Multiresolution Intrinsic Segmentation Template (MIST) and largest available resolution (444 brain parcels).

2. **ROI:**
   - A binary mask of the visual network was extracted from MIST at resolution 7. Voxel-wise time series were extracted for all voxels present in this mask, using the NiftiMasker masker from Nilearn. Note that the location of the mask was based on non-linear registration only, and did not use subject-specific segmentation of the grey matter. The exact same number of voxels (6728) was thus present in the mask for all subjectsâ€™ data.

3. **Whole Brain:**
   - The brain mask generated by the fMRIprep pipeline based on the structural scans of each participant was resampled at the resolution of the fMRI data. This mask included both grey matter, white matter, cerebro-spinal fluid but excluded all tissues surrounding the brain. Voxel-wise time series of all voxels included in the mask were extracted, again using the NiftiMasker masker from Nilearn. As the brain mask was subject-specific, the number of voxels in the mask varied slightly across subjects.

## Extracting VGG16 Features of Dynamic Visual Stimuli

For each fMRI time sample, we extracted the stimulus video frames corresponding to the 4 TRs immediately preceding each fMRI sample (equivalent to a window of 4 x 1.49 = 5.96s duration). This operation was done to take into account the known delayed, convolutional nature of the relationship between the visual stimulus and the hemodynamic response. Each frame was resampled to a (224, 224, 3) array and fed into VGG16 to extract 4096 features from the last layer. The features of the 4 TRs were concatenated, resulting in a single feature vector of length 16384.

## Citation Information

If you are utilizing the generated numpy files in this directory, please ensure to cite the paper titled "Scaling up ridge regression for brain encoding in a massive individual fMRI dataset" by Ahmadi, S., Bellec, P., and Glatard, T. (2024). The paper is available as an arXiv preprint:

Ahmadi, S., Bellec, P., & Glatard, T. (2024). Scaling up ridge regression for brain encoding in a massive individual fMRI dataset. arXiv preprint arXiv:2403.19421. [Link to Paper](https://arxiv.org/pdf/2403.19421.pdf)
